{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np \n",
    "\n",
    "csv.register_dialect('myDialect',delimiter = '\\t',skipinitialspace=True)\n",
    "# Read data\n",
    "data_table = []\n",
    "# Opening File Data from Source\n",
    "with open('Fisher.txt', 'r') as csvFile:\n",
    "    reader = csv.reader(csvFile, dialect='myDialect')\n",
    "    data_table = list(reader)\n",
    "csvFile.close()\n",
    "\n",
    "header = data_table[0]\n",
    "del data_table[0]\n",
    "data = np.zeros((len(data_table), len(data_table[0])))\n",
    "\n",
    "# Reading Data from file\n",
    "for i in range(0,len(data_table)):\n",
    "    tmp = data_table[i]\n",
    "    for j in range(0,len(tmp)):\n",
    "        data[i,j] = int(tmp[j])\n",
    "        \n",
    "# Split class\n",
    "setosa = data[data[:,0] == 0]\n",
    "verginica = data[data[:,0] == 1]\n",
    "versicolor = data[data[:,0] == 2]\n",
    "\n",
    "# Get index for splitting data 80% - 20%\n",
    "data_split = 0.8\n",
    "samples_setosa = int(round(setosa.shape[0]*data_split))\n",
    "samples_verginica = int(round(verginica.shape[0]*data_split))\n",
    "samples_versicolor = int(round(versicolor.shape[0]*data_split))\n",
    "\n",
    "# Seperate training dataset\n",
    "train_setosa = setosa[0:samples_setosa,:]   \n",
    "train_verginica = verginica[0:samples_verginica,:]\n",
    "train_versicolor = versicolor[0:samples_versicolor,:] \n",
    "\n",
    "train_data = np.concatenate((train_setosa,train_verginica, train_versicolor), axis=0)\n",
    "\n",
    "# Seperate test dataset\n",
    "test_setosa = setosa[samples_setosa:,:]\n",
    "test_verginica = verginica[samples_verginica:,:]\n",
    "test_versicolor = versicolor[samples_versicolor:,:]\n",
    "\n",
    "test_data = np.concatenate((test_setosa,test_verginica, test_versicolor), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 1 - Minimum Distance Classifier (Baseline):\n",
      "Accuracy for Euclidean distance: 0.933333\n",
      "Accuracy for Manhattan distance: 0.900000\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compute the mean of all the classes\n",
    "setosa_mean= np.mean(train_setosa[:,1:], axis=0)\n",
    "verginica_mean= np.mean(train_verginica[:,1:], axis=0)\n",
    "versicolor_mean= np.mean(train_versicolor[:,1:], axis=0)\n",
    "\n",
    "acu = 0\n",
    "acu2 = 0\n",
    "\n",
    "for i in range(0, test_data.shape[0]):\n",
    "    #Take Current Sample\n",
    "    s = test_data[i,1:] \n",
    "    \n",
    "    #Compute Euclidean distances\n",
    "    dist1 = np.sqrt(((s[0]-setosa_mean[0])**2) + ((s[1]-setosa_mean[1])**2) + ((s[2]-setosa_mean[2])**2) + ((s[3]-setosa_mean[3])**2))\n",
    "    dist2 = np.sqrt(((s[0]-verginica_mean[0])**2) + ((s[1]-verginica_mean[1])**2) + ((s[2]-verginica_mean[2])**2) + ((s[3]-verginica_mean[3])**2))\n",
    "    dist3 = np.sqrt(((s[0]-versicolor_mean[0])**2) + ((s[1]-versicolor_mean[1])**2) + ((s[2]-versicolor_mean[2])**2) + ((s[3]-versicolor_mean[3])**2))\n",
    "\n",
    "    # Temporarily store distances in an array and sort find the indices that sort the array\n",
    "    d = np.array([dist1, dist2, dist3])\n",
    "    idx = np.argsort(d)\n",
    "    # The smallest Euclidean distance is the prediction, in this case dist1 refers to setosa, and so on...\n",
    "    predicted_class = idx[0]\n",
    "\n",
    "    if(test_data[i,0] == predicted_class):\n",
    "        acu = acu+1\n",
    "    # Compute Manhattan distance\n",
    "    dist4 = np.absolute(s[0]-setosa_mean[0]) + np.absolute(s[1]-setosa_mean[1]) + np.absolute(s[2]-setosa_mean[2]) + np.absolute(s[3]-setosa_mean[3])\n",
    "    dist5 = np.absolute(s[0]-verginica_mean[0]) + np.absolute(s[1]-verginica_mean[1]) + np.absolute(s[2]-verginica_mean[2]) + np.absolute(s[3]-verginica_mean[3])\n",
    "    dist6 = np.absolute(s[0]-versicolor_mean[0]) + np.absolute(s[1]-versicolor_mean[1]) + np.absolute(s[2]-versicolor_mean[2]) + np.absolute(s[3]-versicolor_mean[3])\n",
    "    \n",
    "    # Temporarily store distances in an array and sort find the indices that sort the array\n",
    "    d2 = np.array([dist4, dist5, dist6])\n",
    "    idx2 = np.argsort(d2)\n",
    "    # The smallest Euclidean distance is the prediction, in this case dist1 refers to setosa, and so on...\n",
    "    predicted_class2 = idx2[0]\n",
    "    \n",
    "    if(test_data[i,0] == predicted_class2):\n",
    "        acu2 = acu2+1   \n",
    "                \n",
    "print(\"Task 1 - Minimum Distance Classifier (Baseline):\")\n",
    "print(\"Accuracy for Euclidean distance: %f\" %(acu/float(test_data.shape[0])))\n",
    "print(\"Accuracy for Manhattan distance: %f\" %(acu2/float(test_data.shape[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 2: PCA and Minimum Distance Classifier:\n",
      "Accuracy for Euclidean distance: 0.966667\n",
      "Accuracy for Manhattan distance: 0.966667\n"
     ]
    }
   ],
   "source": [
    "# Shuffle the data randomly\n",
    "np.random.seed(1222)\n",
    "np.random.shuffle(data)\n",
    "#Split the dataset 80% and 20%\n",
    "data_split = 0.8\n",
    "samples_training = int(round(data.shape[0]*data_split))\n",
    "train_data = data[0:samples_training,:]\n",
    "test_data = data[samples_training:,:]\n",
    "\n",
    "# Save feature data as a vector for training data\n",
    "pw_train = train_data[:,1]\n",
    "pl_train = train_data[:,2]\n",
    "sw_train = train_data[:,3]\n",
    "sl_train = train_data[:,4]\n",
    "\n",
    "# Compute the mean of the training feature data\n",
    "pw_train_mean = np.mean(pw_train)\n",
    "pl_train_mean = np.mean(pl_train)\n",
    "sw_train_mean = np.mean(sw_train)\n",
    "sl_train_mean = np.mean(sl_train)\n",
    "\n",
    "# Shift the data \n",
    "pw_train_shifted = pw_train-pw_train_mean\n",
    "pl_train_shifted = pl_train-pl_train_mean\n",
    "sw_train_shifted = sw_train-sw_train_mean\n",
    "sl_train_shifted = sl_train-sl_train_mean\n",
    "\n",
    "# Save feature data as a vector for test data\n",
    "pw_test = test_data[:,1]\n",
    "pl_test = test_data[:,2]\n",
    "sw_test = test_data[:,3]\n",
    "sl_test = test_data[:,4]\n",
    "\n",
    "# Compute the mean of the test feature data\n",
    "pw_test_mean = np.mean(pw_test)\n",
    "pl_test_mean = np.mean(pl_test)\n",
    "sw_test_mean = np.mean(sw_test)\n",
    "sl_test_mean = np.mean(sl_test)\n",
    "\n",
    "# Shift the data\n",
    "pw_test_shifted = pw_test-pw_test_mean\n",
    "pl_test_shifted = pl_test-pl_test_mean\n",
    "sw_test_shifted = sw_test-sw_test_mean\n",
    "sl_test_shifted = sl_test-sl_test_mean\n",
    "\n",
    "# Compute the covariance matrix\n",
    "cov_mat = np.cov((pw_train_shifted,pl_train_shifted,sw_train_shifted,sl_train_shifted))\n",
    "\n",
    "w, v = np.linalg.eig(cov_mat)\n",
    "\n",
    "# Sort according to eigenvalues\n",
    "index = np.argsort(-w)\n",
    "\n",
    "# Use all eigenvectors for full reconstruction\n",
    "feature_vector = v[:,index]\n",
    "\n",
    "RowFeatureVector = np.transpose(feature_vector)\n",
    "RowZeroMeanData = np.array([pw_train_shifted, pl_train_shifted, sw_train_shifted, sl_train_shifted])\n",
    "RowZeroMeanData_test = np.array([pw_test_shifted, pl_test_shifted, sw_test_shifted, sl_test_shifted])\n",
    "\n",
    "FinalData = np.transpose(np.matmul(RowFeatureVector, RowZeroMeanData))\n",
    "FinalData_test = np.transpose(np.matmul(RowFeatureVector, RowZeroMeanData_test))\n",
    "\n",
    "#Split class\n",
    "# this is for training data\n",
    "final_setosa = FinalData[train_data[:,0] == 0,:]\n",
    "final_verginica = FinalData[train_data[:,0] == 1,:]\n",
    "final_versicolor = FinalData[train_data[:,0] == 2,:]\n",
    "\n",
    "#get class mean value\n",
    "final_setosa_mean= np.mean(final_setosa, axis=0)\n",
    "final_verginica_mean= np.mean(final_verginica, axis=0)\n",
    "final_versicolor_mean= np.mean(final_versicolor, axis=0)\n",
    "\n",
    "\n",
    "final_acu = 0\n",
    "final_acu2 = 0\n",
    "\n",
    "for i in range(0, FinalData_test.shape[0]):\n",
    "    #L2 norm\n",
    "    sample = FinalData_test[i,:] #smaple\n",
    "    #Euclidean distance\n",
    "    distance1 = np.sqrt(((sample[0]-final_setosa_mean[0])**2) + ((sample[1]-final_setosa_mean[1])**2) + ((sample[2]-final_setosa_mean[2])**2) + ((sample[3]-final_setosa_mean[3])**2))\n",
    "    distance2 = np.sqrt(((sample[0]-final_verginica_mean[0])**2) + ((sample[1]-final_verginica_mean[1])**2) + ((sample[2]-final_verginica_mean[2])**2) + ((sample[3]-final_verginica_mean[3])**2))\n",
    "    distance3 = np.sqrt(((sample[0]-final_versicolor_mean[0])**2) + ((sample[1]-final_versicolor_mean[1])**2) + ((sample[2]-final_versicolor_mean[2])**2) + ((sample[3]-final_versicolor_mean[3])**2))\n",
    "\n",
    "    final_distance = np.array([distance1, distance2, distance3])\n",
    "    final_idx = np.argsort(final_distance)\n",
    "    final_predicted_class = final_idx[0]\n",
    "\n",
    "    if(test_data[i,0] == final_predicted_class):\n",
    "        final_acu = final_acu+1\n",
    "\n",
    "    #Manhattan distance\n",
    "    distance4 = np.absolute(sample[0]-final_setosa_mean[0]) + np.absolute(sample[1]-final_setosa_mean[1]) + np.absolute(sample[2]-final_setosa_mean[2]) + np.absolute(sample[3]-final_setosa_mean[3])\n",
    "    distance5 = np.absolute(sample[0]-final_verginica_mean[0]) + np.absolute(sample[1]-final_verginica_mean[1]) + np.absolute(sample[2]-final_verginica_mean[2]) + np.absolute(sample[3]-final_verginica_mean[3])\n",
    "    distance6 = np.absolute(sample[0]-final_versicolor_mean[0]) + np.absolute(sample[1]-final_versicolor_mean[1]) + np.absolute(sample[2]-final_versicolor_mean[2]) + np.absolute(sample[3]-final_versicolor_mean[3])\n",
    "    \n",
    "    final_distance2 = np.array([distance4, distance5, distance6])\n",
    "    final_idx2 = np.argsort(final_distance2)\n",
    "    final_predicted_class2 = final_idx2[0]\n",
    "    \n",
    "    if(test_data[i,0] == final_predicted_class2):\n",
    "        final_acu2 = final_acu2+1   \n",
    "\n",
    "print(\"Task 2: PCA and Minimum Distance Classifier:\")\n",
    "print(\"Accuracy for Euclidean distance: %f\" %(final_acu/float(test_data.shape[0])))\n",
    "print(\"Accuracy for Manhattan distance: %f\" %(final_acu2/float(test_data.shape[0])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
